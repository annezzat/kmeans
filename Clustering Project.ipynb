{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35roXDEMudbw"
      },
      "source": [
        "# GUC Clustering Project "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCwbCzREudb1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIiItKbYudb2"
      },
      "source": [
        "**Objective:** \n",
        "The objective of this project teach students how to apply clustering to real data sets\n",
        "\n",
        "The projects aims to teach student: \n",
        "* Which clustering approach to use\n",
        "* Compare between Kmeans, Hierarchal, DBScan, and Gaussian Mixtures  \n",
        "* How to tune the parameters of each data approach\n",
        "* What is the effect of different distance functions (optional) \n",
        "* How to evaluate clustering approachs \n",
        "* How to display the output\n",
        "* What is the effect of normalizing the data \n",
        "\n",
        "Students in this project will use ready-made functions from Sklearn, plotnine, numpy and pandas \n",
        " \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MtHElDYdudb3"
      },
      "outputs": [],
      "source": [
        "# if plotnine is not installed in Jupter then use the following command to install it \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RHS5ZoQudb4"
      },
      "source": [
        "Running this project require the following imports "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QrueqJenudb5"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import seaborn as sns \n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn.preprocessing as prep\n",
        "from sklearn.datasets import make_blobs\n",
        "from plotnine import *   \n",
        "# StandardScaler is a function to normalize the data \n",
        "# You may also check MinMaxScaler and MaxAbsScaler \n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "from sklearn.cluster import DBSCAN\n",
        "from matplotlib.colors import LogNorm\n",
        "from matplotlib.cm import viridis\n",
        "\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.mixture import GaussianMixture\n",
        "\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ju2Zj6-nudb5"
      },
      "outputs": [],
      "source": [
        "# # helper function that allows us to display data in 2 dimensions an highlights the clusters\n",
        "# def display_cluster(X,km=[],num_clusters=0):\n",
        "#     color = [\n",
        "#     '#1f77b4',  # Blue\n",
        "#     '#ff7f0e',  # Orange\n",
        "#     '#2ca02c',  # Green\n",
        "#     '#d62728',  # Red\n",
        "#     '#9467bd',  # Purple\n",
        "#     '#8c564b',  # Brown\n",
        "#     '#e377c2',  # Pink\n",
        "#     '#7f7f7f',  # Gray\n",
        "#     '#17becf',  # Cyan\n",
        "#     '#bcbd22'   # Lime\n",
        "#     ]\n",
        "#     alpha = 0.5  #color obaque\n",
        "#     s = 20\n",
        "#     if num_clusters == 0:\n",
        "#         plt.scatter(X[:,0],X[:,1],c = color[0],alpha = alpha,s = s)\n",
        "#     else:\n",
        "#         for i in range(num_clusters):\n",
        "#             plt.scatter(X[km.labels_==i,0],X[km.labels_==i,1],c = color[i],alpha = alpha,s=s)\n",
        "#             plt.scatter(km.cluster_centers_[i][0],km.cluster_centers_[i][1],c = color[i], marker = 'x', s = 100)\n",
        "#     plt.show()\n",
        "\n",
        "# # helper function that allows us to display data in 2 dimensions an highlights the clusters\n",
        "# def display_db(X,km=[],num_clusters=0):\n",
        "#     color = [\n",
        "#     '#1f77b4',  # Blue\n",
        "#     '#ff7f0e',  # Orange\n",
        "#     '#2ca02c',  # Green\n",
        "#     '#d62728',  # Red\n",
        "#     '#9467bd',  # Purple\n",
        "#     '#8c564b',  # Brown\n",
        "#     '#e377c2',  # Pink\n",
        "#     '#7f7f7f',  # Gray\n",
        "#     '#17becf',  # Cyan\n",
        "#     '#bcbd22',   # Lime\n",
        "#     '#aec7e8',  # Light blue\n",
        "#     '#ffbb78',  # Light orange\n",
        "#     '#98df8a',  # Light green\n",
        "#     '#ff9896',  # Light red\n",
        "#     '#c5b0d5',  # Light purple\n",
        "#     '#c49c94',  # Light brown\n",
        "#     '#f7b6d2',  # Light pink\n",
        "#     '#c7c7c7',  # Light gray\n",
        "#     '#9edae5',  # Light cyan\n",
        "#     '#dbdb8d'   # Light lime\n",
        "#     ]\n",
        "#     alpha = 0.5  #color obaque\n",
        "#     s = 20\n",
        "#     if num_clusters == 0:\n",
        "#         plt.scatter(X[:,0],X[:,1],c = color[0],alpha = alpha,s = s)\n",
        "#     else:\n",
        "#         for i in np.unique(km.labels_):\n",
        "#             if i == -1:\n",
        "#                 plt.scatter(X[km.labels_==i,0],X[km.labels_==i,1],c = '#000000',alpha = alpha,s=s)\n",
        "#             plt.scatter(X[km.labels_==i,0],X[km.labels_==i,1],c = color[i],alpha = alpha,s=s)\n",
        "#             #plt.scatter(km.cluster_centers_[i][0],km.cluster_centers_[i][1],c = color[i], marker = 'x', s = 100)\n",
        "#     plt.show()\n",
        "\n",
        "# def display_gmm(gmm, X, n_components=2, levels=10, cmap=viridis):\n",
        "    \n",
        "#     # Create a meshgrid to plot the contours\n",
        "#     x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "#     y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "#     xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100), np.linspace(y_min, y_max, 100))\n",
        "    \n",
        "#     # Predict the GMM clusters for each point in the meshgrid\n",
        "#     Z = -gmm.score_samples(np.c_[xx.ravel(), yy.ravel()])\n",
        "#     Z = Z.reshape(xx.shape)\n",
        "    \n",
        "#     # Plot the contour map with different colors for each cluster and multiple contour levels\n",
        "#     plt.figure(figsize=(8, 6))\n",
        "#     plt.contour(xx, yy, Z, levels=np.logspace(0, levels, num=20*levels), cmap=cmap, norm=LogNorm())\n",
        "#     plt.scatter(X[:, 0], X[:, 1], marker='o', c=gmm.predict(X), cmap=cmap, alpha=0.7)\n",
        "#     plt.colorbar()\n",
        "#     plt.title('GMM Contour Map with Clusters')\n",
        "#     plt.xlabel('Feature 1')\n",
        "#     plt.ylabel('Feature 2')\n",
        "#     plt.show()\n",
        "\n",
        "# def display_gmm2(gmm, X, n_components=2, levels=10, cmap='viridis',title=''):\n",
        "\n",
        "#     n_dims = X.shape[1]\n",
        "\n",
        "#     # Create subplots for each pair of dimensions\n",
        "#     fig, axs = plt.subplots(n_dims - 1, n_dims - 1, figsize=(12, 12))\n",
        "\n",
        "#     for i in range(n_dims - 1):\n",
        "#         for j in range(i + 1, n_dims):\n",
        "#             # Create a meshgrid for the current pair of dimensions\n",
        "#             x_min, x_max = X[:, i].min() - 1, X[:, i].max() + 1\n",
        "#             y_min, y_max = X[:, j].min() - 1, X[:, j].max() + 1\n",
        "#             xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100), np.linspace(y_min, y_max, 100))\n",
        "\n",
        "#             # Predict the GMM clusters for each point in the meshgrid\n",
        "#             points = np.c_[xx.ravel(), yy.ravel()]\n",
        "#             Z = -gmm.score_samples(np.hstack((points, np.zeros((len(points), n_dims - 2)))))\n",
        "\n",
        "#             Z = Z.reshape(xx.shape)\n",
        "\n",
        "#             # Plot the contour map with different colors for each cluster and multiple contour levels\n",
        "#             axs[i, j - 1].contour(xx, yy, Z, levels=np.logspace(0, levels, num=20 * levels), cmap=cmap, norm=LogNorm())\n",
        "#             axs[i, j - 1].scatter(X[:, i], X[:, j], marker='o', c=gmm.predict(X), cmap=cmap, alpha=0.7)\n",
        "#             axs[i, j - 1].set_title(title)\n",
        "#             axs[i, j - 1].set_xlabel(f'Feature {i + 1}')\n",
        "#             axs[i, j - 1].set_ylabel(f'Feature {j + 1}')\n",
        "\n",
        "#     plt.tight_layout()\n",
        "#     plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZnIbT3Mudb6"
      },
      "source": [
        "## Multi Blob Data Set \n",
        "* The Data Set generated below has 6 cluster with varying number of users and varing densities\n",
        "* Cluster the data set below using \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JeSqG318udb7",
        "outputId": "078fad92-3073-4558-b1e8-f0acd8d85d34"
      },
      "outputs": [],
      "source": [
        "plt.rcParams['figure.figsize'] = [8,8]\n",
        "sns.set_style(\"whitegrid\")\n",
        "sns.set_context(\"talk\")\n",
        "\n",
        "n_bins = 6  \n",
        "centers = [(-3, -3), (0, 0), (5,2.5),(-1, 4), (4, 6), (9,7)]\n",
        "Multi_blob_Data, y = make_blobs(n_samples=[100,150, 300, 400,300, 200], n_features=2, cluster_std=[1.3,0.6, 1.2, 1.7,0.9,1.7],\n",
        "                  centers=centers, shuffle=False, random_state=42)\n",
        "display_cluster(Multi_blob_Data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDSIGjubudb8"
      },
      "source": [
        "### Kmeans \n",
        "* Use Kmeans with different values of K to cluster the above data \n",
        "* Display the outcome of each value of K \n",
        "* Plot distortion function versus K and choose the approriate value of k \n",
        "* Plot the silhouette_score versus K and use it to choose the best K \n",
        "* Store the silhouette_score for the best K for later comparison with other clustering techniques. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Ne3KmtPudb9"
      },
      "outputs": [],
      "source": [
        "# inertias = []\n",
        "# silhouette_avg = []\n",
        "# for i in range(2,11):\n",
        "#     kmeans = KMeans(n_clusters=i) \n",
        "#     kmeans.fit(Multi_blob_Data)\n",
        "#     print (\"num of clusters:\" , i)\n",
        "#     display_cluster(Multi_blob_Data,kmeans,i)\n",
        "#     inertias.append(kmeans.inertia_)\n",
        "#     silhouette_avg.append(silhouette_score(Multi_blob_Data, kmeans.labels_)) \n",
        "\n",
        "# plt.plot(range(2,11), inertias, marker='o')\n",
        "# plt.title('Elbow method')\n",
        "# plt.xlabel('Number of clusters')\n",
        "# plt.ylabel('Inertia')\n",
        "# plt.show()\n",
        "\n",
        "#  # silhouette score\n",
        "\n",
        "# print(silhouette_avg)\n",
        "# plt.plot(range(2,11),silhouette_avg, marker='o')\n",
        "# plt.xlabel(\"Values of K\") \n",
        "# plt.ylabel(\"Silhouette score\") \n",
        "# plt.title(\"Silhouette analysis For Optimal k\")\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kE7dvpOAudb9"
      },
      "source": [
        "### Hierarchal Clustering\n",
        "* Use AgglomerativeClustering function to  to cluster the above data \n",
        "* In the  AgglomerativeClustering change the following parameters \n",
        "    * Affinity (use euclidean, manhattan and cosine)\n",
        "    * Linkage( use average and single )\n",
        "    * Distance_threshold (try different)\n",
        "* For each of these trials plot the Dendograph , calculate the silhouette_score and display the resulting clusters  \n",
        "* Find the set of paramters that would find result in the best silhouette_score and store this score for later comparison with other clustering techniques. \n",
        "* Record your observation "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3O_6WwKoudb-"
      },
      "outputs": [],
      "source": [
        "# silhouette_avg = []\n",
        "\n",
        "# #cluster = AgglomerativeClustering(n_clusters=None, linkage='single', distance_threshold=0)\n",
        "# linkage_data = linkage(Multi_blob_Data, method='single', metric='euclidean')\n",
        "# dendrogram(linkage_data)\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "# num_clusters = []\n",
        "# silhouette_scores = []\n",
        "\n",
        "# distance_threshold =[0.25,0.5,0.75,1,1.25,1.5,1.75,2]\n",
        "# for threshold in distance_threshold:\n",
        "#     cluster = AgglomerativeClustering(n_clusters=None, metric='euclidean', linkage='single', distance_threshold=threshold)\n",
        "#     cluster.fit(Multi_blob_Data)\n",
        "#     labels = cluster.labels_\n",
        "#     num_clusters.append(len(np.unique(labels)))\n",
        "#     silhouette_avg = silhouette_score(Multi_blob_Data, labels)\n",
        "#     silhouette_scores.append(silhouette_avg)\n",
        "\n",
        "# # Plotting the results\n",
        "# plt.plot(distance_threshold, silhouette_scores, marker='o')\n",
        "# plt.xlabel('Distance Threshold')\n",
        "# plt.ylabel('Silhouette Score')\n",
        "# plt.title('Silhouette Score vs Distance Threshold')\n",
        "# plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# silhouette_avg = []\n",
        "# linkage_data = linkage(Multi_blob_Data, method='average', metric='euclidean')\n",
        "# dendrogram(linkage_data)\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "# num_clusters = []\n",
        "# silhouette_scores = []\n",
        "\n",
        "# distance_threshold =[1,2,3,4,5,6,7,8]\n",
        "# for threshold in distance_threshold:\n",
        "#     cluster = AgglomerativeClustering(n_clusters=None, metric='euclidean', linkage='average', distance_threshold=threshold)\n",
        "#     cluster.fit(Multi_blob_Data)\n",
        "#     labels = cluster.labels_\n",
        "#     num_clusters.append(len(np.unique(labels)))\n",
        "#     silhouette_avg = silhouette_score(Multi_blob_Data, labels)\n",
        "#     silhouette_scores.append(silhouette_avg)\n",
        "\n",
        "# # Plotting the results\n",
        "# plt.plot(distance_threshold, silhouette_scores, marker='o')\n",
        "# plt.xlabel('Distance Threshold')\n",
        "# plt.ylabel('Silhouette Score')\n",
        "# plt.title('Silhouette Score vs Distance Threshold')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# linkage_data = linkage(Multi_blob_Data, method='single', metric='cityblock')\n",
        "# dendrogram(linkage_data)\n",
        "# plt.show()\n",
        "\n",
        "# num_clusters = []\n",
        "# silhouette_scores = []\n",
        "\n",
        "# distance_threshold =[0.25,0.5,0.75,1,1.25,1.5,1.75,2]\n",
        "# for threshold in distance_threshold:\n",
        "#     cluster = AgglomerativeClustering(n_clusters=None, metric='cityblock', linkage='single', distance_threshold=threshold)\n",
        "#     cluster.fit(Multi_blob_Data)\n",
        "#     labels = cluster.labels_\n",
        "#     num_clusters.append(len(np.unique(labels)))\n",
        "#     silhouette_avg = silhouette_score(Multi_blob_Data, labels)\n",
        "#     silhouette_scores.append(silhouette_avg)\n",
        "\n",
        "# # Plotting the results\n",
        "# plt.plot(distance_threshold, silhouette_scores, marker='o')\n",
        "# plt.xlabel('Distance Threshold')\n",
        "# plt.ylabel('Silhouette Score')\n",
        "# plt.title('Silhouette Score vs Distance Threshold')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# linkage_data = linkage(Multi_blob_Data, method='average', metric='cityblock')\n",
        "# dendrogram(linkage_data)\n",
        "# plt.show()\n",
        "\n",
        "# num_clusters = []\n",
        "# silhouette_scores = []\n",
        "\n",
        "# distance_threshold =[1,2,3,4,5,6,7,8,9,10]\n",
        "# for threshold in distance_threshold:\n",
        "#     cluster = AgglomerativeClustering(n_clusters=None, metric='cityblock', linkage='average', distance_threshold=threshold)\n",
        "#     cluster.fit(Multi_blob_Data)\n",
        "#     labels = cluster.labels_\n",
        "#     num_clusters.append(len(np.unique(labels)))\n",
        "#     silhouette_avg = silhouette_score(Multi_blob_Data, labels)\n",
        "#     silhouette_scores.append(silhouette_avg)\n",
        "\n",
        "# # Plotting the results\n",
        "# plt.plot(distance_threshold, silhouette_scores, marker='o')\n",
        "# plt.xlabel('Distance Threshold')\n",
        "# plt.ylabel('Silhouette Score')\n",
        "# plt.title('Silhouette Score vs Distance Threshold')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# linkage_data = linkage(Multi_blob_Data, method='single', metric='cosine')\n",
        "# dendrogram(linkage_data)\n",
        "# plt.show()\n",
        "\n",
        "# num_clusters = []\n",
        "# silhouette_scores = []\n",
        "\n",
        "# distance_threshold =[0.001,0.002,0.003,0.004,0.005,0.006,0.007,0.008,0.009]\n",
        "# for threshold in distance_threshold:\n",
        "#     cluster = AgglomerativeClustering(n_clusters=None, metric='cosine', linkage='single', distance_threshold=threshold)\n",
        "#     cluster.fit(Multi_blob_Data)\n",
        "#     labels = cluster.labels_\n",
        "#     num_clusters.append(len(np.unique(labels)))\n",
        "#     silhouette_avg = silhouette_score(Multi_blob_Data, labels)\n",
        "#     silhouette_scores.append(silhouette_avg)\n",
        "\n",
        "# # Plotting the results\n",
        "# plt.plot(distance_threshold, silhouette_scores, marker='o')\n",
        "# plt.xlabel('Distance Threshold')\n",
        "# plt.ylabel('Silhouette Score')\n",
        "# plt.title('Silhouette Score vs Distance Threshold')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# linkage_data = linkage(Multi_blob_Data, method='average', metric='cosine')\n",
        "# dendrogram(linkage_data)\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "# num_clusters = []\n",
        "# silhouette_scores = []\n",
        "\n",
        "# distance_threshold =[0.2,0.4,0.6,0.8,1.0,1.2,1.4,1.6]\n",
        "# for threshold in distance_threshold:\n",
        "#     cluster = AgglomerativeClustering(n_clusters=None, metric='cosine', linkage='average', distance_threshold=threshold)\n",
        "#     cluster.fit(Multi_blob_Data)\n",
        "#     labels = cluster.labels_\n",
        "#     num_clusters.append(len(np.unique(labels)))\n",
        "#     silhouette_avg = silhouette_score(Multi_blob_Data, labels)\n",
        "#     silhouette_scores.append(silhouette_avg)\n",
        "\n",
        "# # Plotting the results\n",
        "# plt.plot(distance_threshold, silhouette_scores, marker='o')\n",
        "# plt.xlabel('Distance Threshold')\n",
        "# plt.ylabel('Silhouette Score')\n",
        "# plt.title('Silhouette Score vs Distance Threshold')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myJE7vQKudb-"
      },
      "source": [
        "### DBScan\n",
        "* Use DBScan function to  to cluster the above data \n",
        "* In the  DBscan change the following parameters \n",
        "    * EPS (from 0.1 to 3)\n",
        "    * Min_samples (from 5 to 25)\n",
        "* Plot the silhouette_score versus the variation in the EPS and the min_samples\n",
        "* Plot the resulting Clusters in this case \n",
        "* Find the set of paramters that would find result in the best silhouette_score and store this score for later comparison with other clustering techniques. \n",
        "* Record your observations and comments "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QiQtpAt5udb_"
      },
      "outputs": [],
      "source": [
        "# # Define range of EPS and min_samples values\n",
        "# eps_values = np.arange(0.3, 1.3, 0.1)\n",
        "# min_samples_values = np.arange(5, 26, 5)\n",
        "\n",
        "# # Initialize variables to store best parameters and corresponding silhouette score\n",
        "# best_eps = None\n",
        "# best_min_samples = None\n",
        "# best_score = -1\n",
        "\n",
        "# # Initialize lists to store silhouette scores for plotting\n",
        "# silhouette_scores = []\n",
        "\n",
        "# # Loop over different combinations of EPS and min_samples\n",
        "# for eps in eps_values:\n",
        "#     for min_samples in min_samples_values:\n",
        "#         # Perform DBScan clustering\n",
        "#         dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
        "#         labels = dbscan.fit_predict(Multi_blob_Data)\n",
        "#         if(len(np.unique(dbscan.labels_)) < 20):\n",
        "#             display_db(Multi_blob_Data,dbscan,num_clusters = len(np.unique(dbscan.labels_)))\n",
        "#         # Compute silhouette score\n",
        "#         if(len(np.unique(dbscan.labels_)) > 1):\n",
        "#             score = silhouette_score(Multi_blob_Data, labels)\n",
        "#             silhouette_scores.append(score)\n",
        "        \n",
        "#         # Check if current parameters yield the best silhouette score\n",
        "#         if score > best_score:\n",
        "#             best_eps = eps\n",
        "#             best_min_samples = min_samples\n",
        "#             best_score = score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ip16g1QFudb_"
      },
      "source": [
        "### Gaussian Mixture\n",
        "* Use GaussianMixture function to cluster the above data \n",
        "* In GMM change the covariance_type and check the difference in the resulting proabability fit \n",
        "* Use a 2D contour plot to plot the resulting distribution (the components of the GMM) as well as the total Gaussian mixture "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Fit a Gaussian Mixture Model\n",
        "# silhouettes = []\n",
        "# for i in range(2,10):\n",
        "#     gmm = GaussianMixture(n_components=i, covariance_type='full')\n",
        "#     gmm.fit(Multi_blob_Data)\n",
        "#     labels = gmm.predict(Multi_blob_Data)\n",
        "#     silhouette_avg = silhouette_score(Multi_blob_Data, labels)\n",
        "#     silhouettes.append(silhouette_avg)\n",
        "#     display_gmm(gmm,Multi_blob_Data)\n",
        "\n",
        "# # Plot silhouette scores\n",
        "# plt.plot(range(2, 10), silhouettes, marker='o')\n",
        "# plt.xlabel('Number of components')\n",
        "# plt.ylabel('Silhouette Score')\n",
        "# plt.title('Silhouette Score vs Number of Components')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Fit a Gaussian Mixture Model\n",
        "# silhouettes = []\n",
        "# for i in range(2,10):\n",
        "#     gmm = GaussianMixture(n_components=i, covariance_type='tied')\n",
        "#     gmm.fit(Multi_blob_Data)\n",
        "#     labels = gmm.predict(Multi_blob_Data)\n",
        "#     silhouette_avg = silhouette_score(Multi_blob_Data, labels)    \n",
        "#     silhouettes.append(silhouette_avg)\n",
        "#     display_gmm(gmm,Multi_blob_Data)\n",
        "\n",
        "# # Plot silhouette scores\n",
        "# plt.plot(range(2, 10), silhouettes, marker='o')\n",
        "# plt.xlabel('Number of components')\n",
        "# plt.ylabel('Silhouette Score')\n",
        "# plt.title('Silhouette Score vs Number of Components')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fit a Gaussian Mixture Model\n",
        "silhouettes = []\n",
        "for i in range(2,10):\n",
        "    gmm = GaussianMixture(n_components=i, covariance_type='diag')\n",
        "    gmm.fit(Multi_blob_Data)\n",
        "    labels = gmm.predict(Multi_blob_Data)\n",
        "    silhouette_avg = silhouette_score(Multi_blob_Data, labels)    \n",
        "    silhouettes.append(silhouette_avg)\n",
        "    display_gmm(gmm,Multi_blob_Data)\n",
        "\n",
        "# Plot silhouette scores\n",
        "plt.plot(range(2, 10), silhouettes, marker='o')\n",
        "plt.xlabel('Number of components')\n",
        "plt.ylabel('Silhouette Score')\n",
        "plt.title('Silhouette Score vs Number of Components')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fit a Gaussian Mixture Model\n",
        "silhouettes = []\n",
        "for i in range(2,10):\n",
        "    gmm = GaussianMixture(n_components=i, covariance_type='spherical')\n",
        "    gmm.fit(Multi_blob_Data)\n",
        "    labels = gmm.predict(Multi_blob_Data)\n",
        "    silhouette_avg = silhouette_score(Multi_blob_Data, labels)    \n",
        "    silhouettes.append(silhouette_avg)\n",
        "    display_gmm(gmm,Multi_blob_Data)\n",
        "\n",
        "# Plot silhouette scores\n",
        "plt.plot(range(2, 10), silhouettes, marker='o')\n",
        "plt.xlabel('Number of components')\n",
        "plt.ylabel('Silhouette Score')\n",
        "plt.title('Silhouette Score vs Number of Components')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m92lZkkyudb_"
      },
      "source": [
        "## iris data set \n",
        "The iris data set is test data set that is part of the Sklearn module \n",
        "which contains 150 records each with 4 features. All the features are represented by real numbers \n",
        "\n",
        "The data represents three classes \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_QaCWyyCudcA",
        "outputId": "79c14dba-80cf-4d96-e69d-70763b789faf"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "iris_data = load_iris()\n",
        "iris_data.target[[10, 25, 50]]\n",
        "#array([0, 0, 1])\n",
        "list(iris_data.target_names)\n",
        "['setosa', 'versicolor', 'virginica']\n",
        "scaler = StandardScaler()\n",
        "X_normalized = scaler.fit_transform(iris_data.data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyoCVfyMudcA"
      },
      "source": [
        "* Repeat all the above clustering approaches and steps on the above data \n",
        "* Normalize the data then repeat all the above steps \n",
        "* Compare between the different clustering approaches "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Kmeans unnormalized data\n",
        "* Use Kmeans with different values of K to cluster the above data \n",
        "* Display the outcome of each value of K \n",
        "* Plot distortion function versus K and choose the approriate value of k \n",
        "* Plot the silhouette_score versus K and use it to choose the best K \n",
        "* Store the silhouette_score for the best K for later comparison with other clustering techniques. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "inertias = []\n",
        "silhouette_avg = []\n",
        "for i in range(2,11):\n",
        "    kmeans = KMeans(n_clusters=i) \n",
        "    kmeans.fit(iris_data.data)\n",
        "    print (\"num of clusters:\" , i)\n",
        "    display_cluster(iris_data.data,kmeans,i)\n",
        "    inertias.append(kmeans.inertia_)\n",
        "    silhouette_avg.append(silhouette_score(iris_data.data, kmeans.labels_)) \n",
        "\n",
        "plt.plot(range(2,11), inertias, marker='o')\n",
        "plt.title('Elbow method')\n",
        "plt.xlabel('Number of clusters')\n",
        "plt.ylabel('Inertia')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print(silhouette_avg)\n",
        "plt.plot(range(2,11),silhouette_avg, marker='o')\n",
        "plt.xlabel(\"Values of K\") \n",
        "plt.ylabel(\"Silhouette score\") \n",
        "plt.title(\"Silhouette analysis For Optimal k\")\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Kmeans normalized data\n",
        "* Use Kmeans with different values of K to cluster the above data \n",
        "* Display the outcome of each value of K \n",
        "* Plot distortion function versus K and choose the approriate value of k \n",
        "* Plot the silhouette_score versus K and use it to choose the best K \n",
        "* Store the silhouette_score for the best K for later comparison with other clustering techniques. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "inertias = []\n",
        "silhouette_avg = []\n",
        "for i in range(2,11):\n",
        "    kmeans = KMeans(n_clusters=i) \n",
        "    kmeans.fit(X_normalized)\n",
        "    print (\"num of clusters:\" , i)\n",
        "    display_cluster(X_normalized,kmeans,i)\n",
        "    inertias.append(kmeans.inertia_)\n",
        "    silhouette_avg.append(silhouette_score(X_normalized, kmeans.labels_)) \n",
        "\n",
        "plt.plot(range(2,11), inertias, marker='o')\n",
        "plt.title('Elbow method')\n",
        "plt.xlabel('Number of clusters')\n",
        "plt.ylabel('Inertia')\n",
        "plt.show()\n",
        "\n",
        "print(silhouette_avg)\n",
        "plt.plot(range(2,11),silhouette_avg, marker='o')\n",
        "plt.xlabel(\"Values of K\") \n",
        "plt.ylabel(\"Silhouette score\") \n",
        "plt.title(\"Silhouette analysis For Optimal k\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hierarchal Clustering unnormalized data\n",
        "* Use AgglomerativeClustering function to  to cluster the above data \n",
        "* In the  AgglomerativeClustering change the following parameters \n",
        "    * Affinity (use euclidean, manhattan and cosine)\n",
        "    * Linkage( use average and single )\n",
        "    * Distance_threshold (try different)\n",
        "* For each of these trials plot the Dendograph , calculate the silhouette_score and display the resulting clusters  \n",
        "* Find the set of paramters that would find result in the best silhouette_score and store this score for later comparison with other clustering techniques. \n",
        "* Record your observation "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# linkage_data = linkage(iris_data.data, method='single', metric='euclidean')\n",
        "# dendrogram(linkage_data)\n",
        "# plt.show()\n",
        "\n",
        "# num_clusters = []\n",
        "# silhouette_scores = []\n",
        "\n",
        "# distance_threshold =[0.2,0.4,0.6,0.8,1.0,1.2,1.4,1.6]\n",
        "# for threshold in distance_threshold:\n",
        "#     cluster = AgglomerativeClustering(n_clusters=None, metric='euclidean', linkage='single', distance_threshold=threshold)\n",
        "#     cluster.fit(iris_data.data)\n",
        "#     labels = cluster.labels_\n",
        "#     num_clusters.append(len(np.unique(labels)))\n",
        "#     silhouette_avg = silhouette_score(iris_data.data, labels)\n",
        "#     silhouette_scores.append(silhouette_avg)\n",
        "\n",
        "# # Plotting the results\n",
        "# plt.plot(distance_threshold, silhouette_scores, marker='o')\n",
        "# plt.xlabel('Distance Threshold')\n",
        "# plt.ylabel('Silhouette Score')\n",
        "# plt.title('Silhouette Score vs Distance Threshold')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# linkage_data = linkage(iris_data.data, method='average', metric='euclidean')\n",
        "# dendrogram(linkage_data)\n",
        "# plt.show()\n",
        "\n",
        "# num_clusters = []\n",
        "# silhouette_scores = []\n",
        "\n",
        "# distance_threshold =[0.5,1,1.5,2,2.5,3,3.5,4]\n",
        "# for threshold in distance_threshold:\n",
        "#     cluster = AgglomerativeClustering(n_clusters=None, metric='euclidean', linkage='average', distance_threshold=threshold)\n",
        "#     cluster.fit(iris_data.data)\n",
        "#     labels = cluster.labels_\n",
        "#     num_clusters.append(len(np.unique(labels)))\n",
        "#     silhouette_avg = silhouette_score(iris_data.data, labels)\n",
        "#     silhouette_scores.append(silhouette_avg)\n",
        "\n",
        "# # Plotting the results\n",
        "# plt.plot(distance_threshold, silhouette_scores, marker='o')\n",
        "# plt.xlabel('Distance Threshold')\n",
        "# plt.ylabel('Silhouette Score')\n",
        "# plt.title('Silhouette Score vs Distance Threshold')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# linkage_data = linkage(iris_data.data, method='single', metric='cityblock')\n",
        "# dendrogram(linkage_data)\n",
        "# plt.show()\n",
        "\n",
        "# num_clusters = []\n",
        "# silhouette_scores = []\n",
        "\n",
        "# distance_threshold =[0.25,0.5,0.75,1,1.25,1.5,1.75,2,2.25,2.5]\n",
        "# for threshold in distance_threshold:\n",
        "#     cluster = AgglomerativeClustering(n_clusters=None, metric='cityblock', linkage='single', distance_threshold=threshold)\n",
        "#     cluster.fit(iris_data.data)\n",
        "#     labels = cluster.labels_\n",
        "#     num_clusters.append(len(np.unique(labels)))\n",
        "#     silhouette_avg = silhouette_score(iris_data.data, labels)\n",
        "#     silhouette_scores.append(silhouette_avg)\n",
        "\n",
        "# # Plotting the results\n",
        "# plt.plot(distance_threshold, silhouette_scores, marker='o')\n",
        "# plt.xlabel('Distance Threshold')\n",
        "# plt.ylabel('Silhouette Score')\n",
        "# plt.title('Silhouette Score vs Distance Threshold')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# linkage_data = linkage(iris_data.data, method='average', metric='cityblock')\n",
        "# dendrogram(linkage_data)\n",
        "# plt.show()\n",
        "# num_clusters = []\n",
        "# silhouette_scores = []\n",
        "\n",
        "# distance_threshold =[1,1.5,2,2.5,3,4,5,6]\n",
        "# for threshold in distance_threshold:\n",
        "#     cluster = AgglomerativeClustering(n_clusters=None, metric='cityblock', linkage='average', distance_threshold=threshold)\n",
        "#     cluster.fit(iris_data.data)\n",
        "#     labels = cluster.labels_\n",
        "#     num_clusters.append(len(np.unique(labels)))\n",
        "#     silhouette_avg = silhouette_score(iris_data.data, labels)\n",
        "#     silhouette_scores.append(silhouette_avg)\n",
        "\n",
        "# # Plotting the results\n",
        "# plt.plot(distance_threshold, silhouette_scores, marker='o')\n",
        "# plt.xlabel('Distance Threshold')\n",
        "# plt.ylabel('Silhouette Score')\n",
        "# plt.title('Silhouette Score vs Distance Threshold')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# linkage_data = linkage(iris_data.data, method='single', metric='cosine')\n",
        "# dendrogram(linkage_data)\n",
        "# plt.show()\n",
        "\n",
        "# num_clusters = []\n",
        "# silhouette_scores = []\n",
        "\n",
        "# distance_threshold =[0.001,0.002,0.003,0.004,0.005,0.01,0.02]\n",
        "# for threshold in distance_threshold:\n",
        "#     cluster = AgglomerativeClustering(n_clusters=None, metric='cosine', linkage='single', distance_threshold=threshold)\n",
        "#     cluster.fit(iris_data.data)\n",
        "#     labels = cluster.labels_\n",
        "#     num_clusters.append(len(np.unique(labels)))\n",
        "#     silhouette_avg = silhouette_score(iris_data.data, labels)\n",
        "#     silhouette_scores.append(silhouette_avg)\n",
        "\n",
        "# # Plotting the results\n",
        "# plt.plot(distance_threshold, silhouette_scores, marker='o')\n",
        "# plt.xlabel('Distance Threshold')\n",
        "# plt.ylabel('Silhouette Score')\n",
        "# plt.title('Silhouette Score vs Distance Threshold')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# linkage_data = linkage(iris_data.data, method='average', metric='cosine')\n",
        "# dendrogram(linkage_data)\n",
        "# plt.show()\n",
        "\n",
        "# num_clusters = []\n",
        "# silhouette_scores = []\n",
        "\n",
        "# distance_threshold =[0.002,0.004,0.006,0.008,0.01,0.0125,0.015,0.0175,0.02,0.04,0.06,0.08]\n",
        "# for threshold in distance_threshold:\n",
        "#     cluster = AgglomerativeClustering(n_clusters=None, metric='cosine', linkage='average', distance_threshold=threshold)\n",
        "#     cluster.fit(iris_data.data)\n",
        "#     labels = cluster.labels_\n",
        "#     num_clusters.append(len(np.unique(labels)))\n",
        "#     silhouette_avg = silhouette_score(iris_data.data, labels)\n",
        "#     silhouette_scores.append(silhouette_avg)\n",
        "\n",
        "# # Plotting the results\n",
        "# plt.plot(distance_threshold, silhouette_scores, marker='o')\n",
        "# plt.xlabel('Distance Threshold')\n",
        "# plt.ylabel('Silhouette Score')\n",
        "# plt.title('Silhouette Score vs Distance Threshold')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hierarchal Clustering normalized data\n",
        "* Use AgglomerativeClustering function to  to cluster the above data \n",
        "* In the  AgglomerativeClustering change the following parameters \n",
        "    * Affinity (use euclidean, manhattan and cosine)\n",
        "    * Linkage( use average and single )\n",
        "    * Distance_threshold (try different)\n",
        "* For each of these trials plot the Dendograph , calculate the silhouette_score and display the resulting clusters  \n",
        "* Find the set of paramters that would find result in the best silhouette_score and store this score for later comparison with other clustering techniques. \n",
        "* Record your observation "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# linkage_data = linkage(X_normalized, method='single', metric='euclidean')\n",
        "# dendrogram(linkage_data)\n",
        "# plt.show()\n",
        "\n",
        "# num_clusters = []\n",
        "# silhouette_scores = []\n",
        "\n",
        "# distance_threshold =[0.05,0.1,0.15,0.2,0.3,0.4,0.6,0.8,1,1.4]\n",
        "# for threshold in distance_threshold:\n",
        "#     cluster = AgglomerativeClustering(n_clusters=None, metric='euclidean', linkage='single', distance_threshold=threshold)\n",
        "#     cluster.fit(X_normalized)\n",
        "#     labels = cluster.labels_\n",
        "#     num_clusters.append(len(np.unique(labels)))\n",
        "#     silhouette_avg = silhouette_score(X_normalized, labels)\n",
        "#     silhouette_scores.append(silhouette_avg)\n",
        "\n",
        "# # Plotting the results\n",
        "# plt.plot(distance_threshold, silhouette_scores, marker='o')\n",
        "# plt.xlabel('Distance Threshold')\n",
        "# plt.ylabel('Silhouette Score')\n",
        "# plt.title('Silhouette Score vs Distance Threshold')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# linkage_data = linkage(X_normalized, method='average', metric='euclidean')\n",
        "# dendrogram(linkage_data)\n",
        "# plt.show()\n",
        "\n",
        "# num_clusters = []\n",
        "# silhouette_scores = []\n",
        "\n",
        "# distance_threshold =[0.1,0.15,0.2,0.3,0.4,0.6,0.8,1,1.4,1.9,2.9,3.4]\n",
        "# for threshold in distance_threshold:\n",
        "#     cluster = AgglomerativeClustering(n_clusters=None, metric='euclidean', linkage='average', distance_threshold=threshold)\n",
        "#     cluster.fit(X_normalized)\n",
        "#     labels = cluster.labels_\n",
        "#     num_clusters.append(len(np.unique(labels)))\n",
        "#     silhouette_avg = silhouette_score(X_normalized, labels)\n",
        "#     silhouette_scores.append(silhouette_avg)\n",
        "\n",
        "# # Plotting the results\n",
        "# plt.plot(distance_threshold, silhouette_scores, marker='o')\n",
        "# plt.xlabel('Distance Threshold')\n",
        "# plt.ylabel('Silhouette Score')\n",
        "# plt.title('Silhouette Score vs Distance Threshold')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# linkage_data = linkage(X_normalized, method='single', metric='cityblock')\n",
        "# dendrogram(linkage_data)\n",
        "# plt.show()\n",
        "\n",
        "# num_clusters = []\n",
        "# silhouette_scores = []\n",
        "\n",
        "# distance_threshold =[0.1,0.2,0.3,0.4,0.5,0.6,0.8,1,1.2,1.4,2]\n",
        "# for threshold in distance_threshold:\n",
        "#     cluster = AgglomerativeClustering(n_clusters=None, metric='cityblock', linkage='single', distance_threshold=threshold)\n",
        "#     cluster.fit(X_normalized)\n",
        "#     labels = cluster.labels_\n",
        "#     num_clusters.append(len(np.unique(labels)))\n",
        "#     silhouette_avg = silhouette_score(X_normalized, labels)\n",
        "#     silhouette_scores.append(silhouette_avg)\n",
        "\n",
        "# # Plotting the results\n",
        "# plt.plot(distance_threshold, silhouette_scores, marker='o')\n",
        "# plt.xlabel('Distance Threshold')\n",
        "# plt.ylabel('Silhouette Score')\n",
        "# plt.title('Silhouette Score vs Distance Threshold')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# linkage_data = linkage(X_normalized, method='average', metric='cityblock')\n",
        "# dendrogram(linkage_data)\n",
        "# plt.show()\n",
        "\n",
        "# um_clusters = []\n",
        "# silhouette_scores = []\n",
        "\n",
        "# distance_threshold =[0.5,1,1.5,2,2.5,3,4,5,6]\n",
        "# for threshold in distance_threshold:\n",
        "#     cluster = AgglomerativeClustering(n_clusters=None, metric='cityblock', linkage='average', distance_threshold=threshold)\n",
        "#     cluster.fit(X_normalized)\n",
        "#     labels = cluster.labels_\n",
        "#     num_clusters.append(len(np.unique(labels)))\n",
        "#     silhouette_avg = silhouette_score(X_normalized, labels)\n",
        "#     silhouette_scores.append(silhouette_avg)\n",
        "\n",
        "# # Plotting the results\n",
        "# plt.plot(distance_threshold, silhouette_scores, marker='o')\n",
        "# plt.xlabel('Distance Threshold')\n",
        "# plt.ylabel('Silhouette Score')\n",
        "# plt.title('Silhouette Score vs Distance Threshold')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# linkage_data = linkage(X_normalized, method='single', metric='cosine')\n",
        "# dendrogram(linkage_data)\n",
        "# plt.show()\n",
        "\n",
        "# um_clusters = []\n",
        "# silhouette_scores = []\n",
        "\n",
        "# distance_threshold =[0.005,0.01,0.015,0.02,0.03,0.04,0.06,0.08,0.1]\n",
        "# for threshold in distance_threshold:\n",
        "#     cluster = AgglomerativeClustering(n_clusters=None, metric='cosine', linkage='single', distance_threshold=threshold)\n",
        "#     cluster.fit(X_normalized)\n",
        "#     labels = cluster.labels_\n",
        "#     num_clusters.append(len(np.unique(labels)))\n",
        "#     silhouette_avg = silhouette_score(X_normalized, labels)\n",
        "#     silhouette_scores.append(silhouette_avg)\n",
        "\n",
        "# # Plotting the results\n",
        "# plt.plot(distance_threshold, silhouette_scores, marker='o')\n",
        "# plt.xlabel('Distance Threshold')\n",
        "# plt.ylabel('Silhouette Score')\n",
        "# plt.title('Silhouette Score vs Distance Threshold')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# linkage_data = linkage(X_normalized, method='average', metric='cosine')\n",
        "# dendrogram(linkage_data)\n",
        "# plt.show()\n",
        "\n",
        "# um_clusters = []\n",
        "# silhouette_scores = []\n",
        "\n",
        "# distance_threshold =[0.05,0.1,0.2,0.3,0.4,0.6,0.8,1,1.2,1.4]\n",
        "# for threshold in distance_threshold:\n",
        "#     cluster = AgglomerativeClustering(n_clusters=None, metric='cosine', linkage='average', distance_threshold=threshold)\n",
        "#     cluster.fit(X_normalized)\n",
        "#     labels = cluster.labels_\n",
        "#     num_clusters.append(len(np.unique(labels)))\n",
        "#     silhouette_avg = silhouette_score(X_normalized, labels)\n",
        "#     silhouette_scores.append(silhouette_avg)\n",
        "\n",
        "# # Plotting the results\n",
        "# plt.plot(distance_threshold, silhouette_scores, marker='o')\n",
        "# plt.xlabel('Distance Threshold')\n",
        "# plt.ylabel('Silhouette Score')\n",
        "# plt.title('Silhouette Score vs Distance Threshold')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### DBScan Unnormalized data\n",
        "* Use DBScan function to  to cluster the above data \n",
        "* In the  DBscan change the following parameters \n",
        "    * EPS (from 0.1 to 3)\n",
        "    * Min_samples (from 5 to 25)\n",
        "* Plot the silhouette_score versus the variation in the EPS and the min_samples\n",
        "* Plot the resulting Clusters in this case \n",
        "* Find the set of paramters that would find result in the best silhouette_score and store this score for later comparison with other clustering techniques. \n",
        "* Record your observations and comments "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Define range of EPS and min_samples values\n",
        "# eps_values = np.arange(0.3, 1.3, 0.1)\n",
        "# min_samples_values = np.arange(5, 26, 5)\n",
        "\n",
        "# # Initialize variables to store best parameters and corresponding silhouette score\n",
        "# best_eps = None\n",
        "# best_min_samples = None\n",
        "# best_score = -1\n",
        "\n",
        "# # Initialize lists to store silhouette scores for plotting\n",
        "# silhouette_scores = []\n",
        "\n",
        "# # Loop over different combinations of EPS and min_samples\n",
        "# for eps in eps_values:\n",
        "#     for min_samples in min_samples_values:\n",
        "#         # Perform DBScan clustering\n",
        "#         dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
        "#         labels = dbscan.fit_predict(iris_data.data)\n",
        "#         print(labels)\n",
        "#         if(len(np.unique(dbscan.labels_)) < 20):\n",
        "#             display_db(iris_data.data,dbscan,num_clusters = len(np.unique(dbscan.labels_)))\n",
        "#         # Compute silhouette score\n",
        "#         if(len(np.unique(dbscan.labels_)) > 1):\n",
        "#             score = silhouette_score(iris_data.data, labels)\n",
        "#             silhouette_scores.append(score)\n",
        "        \n",
        "#         # Check if current parameters yield the best silhouette score\n",
        "#         if score > best_score:\n",
        "#             best_eps = eps\n",
        "#             best_min_samples = min_samples\n",
        "#             best_score = score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### DBScan normalized data\n",
        "* Use DBScan function to  to cluster the above data \n",
        "* In the  DBscan change the following parameters \n",
        "    * EPS (from 0.1 to 3)\n",
        "    * Min_samples (from 5 to 25)\n",
        "* Plot the silhouette_score versus the variation in the EPS and the min_samples\n",
        "* Plot the resulting Clusters in this case \n",
        "* Find the set of paramters that would find result in the best silhouette_score and store this score for later comparison with other clustering techniques. \n",
        "* Record your observations and comments "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Define range of EPS and min_samples values\n",
        "# eps_values = np.arange(0.3, 1.3, 0.1)\n",
        "# min_samples_values = np.arange(5, 26, 5)\n",
        "\n",
        "# # Initialize variables to store best parameters and corresponding silhouette score\n",
        "# best_eps = None\n",
        "# best_min_samples = None\n",
        "# best_score = -1\n",
        "\n",
        "# # Initialize lists to store silhouette scores for plotting\n",
        "# silhouette_scores = []\n",
        "\n",
        "# # Loop over different combinations of EPS and min_samples\n",
        "# for eps in eps_values:\n",
        "#     for min_samples in min_samples_values:\n",
        "#         # Perform DBScan clustering\n",
        "#         dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
        "#         labels = dbscan.fit_predict(X_normalized)\n",
        "#         print(labels)\n",
        "#         if(len(np.unique(dbscan.labels_)) < 20):\n",
        "#             display_db(X_normalized,dbscan,num_clusters = len(np.unique(dbscan.labels_)))\n",
        "#         # Compute silhouette score\n",
        "#         if(len(np.unique(dbscan.labels_)) > 1):\n",
        "#             score = silhouette_score(X_normalized, labels)\n",
        "#             silhouette_scores.append(score)\n",
        "        \n",
        "#         # Check if current parameters yield the best silhouette score\n",
        "#         if score > best_score:\n",
        "#             best_eps = eps\n",
        "#             best_min_samples = min_samples\n",
        "#             best_score = score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Gaussian Mixture unnormalized\n",
        "* Use GaussianMixture function to cluster the above data \n",
        "* In GMM change the covariance_type and check the difference in the resulting proabability fit \n",
        "* Use a 2D contour plot to plot the resulting distribution (the components of the GMM) as well as the total Gaussian mixture "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Fit a Gaussian Mixture Model\n",
        "# silhouettes = []\n",
        "# for i in range(2,10):\n",
        "#     gmm = GaussianMixture(n_components=i, covariance_type='full')\n",
        "#     gmm.fit(iris_data.data)\n",
        "#     labels = gmm.predict(iris_data.data)\n",
        "#     silhouette_avg = silhouette_score(iris_data.data, labels)\n",
        "#     silhouettes.append(silhouette_avg)\n",
        "#     X_two_features = iris_data.data[:, :2]\n",
        "#     display_gmm2(gmm,iris_data.data)\n",
        "\n",
        "# # Plot silhouette scores\n",
        "# plt.plot(range(2, 10), silhouettes, marker='o')\n",
        "# plt.xlabel('Number of components')\n",
        "# plt.ylabel('Silhouette Score')\n",
        "# plt.title('Silhouette Score vs Number of Components')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Fit a Gaussian Mixture Model\n",
        "# silhouettes = []\n",
        "# for i in range(2,10):\n",
        "#     gmm = GaussianMixture(n_components=i, covariance_type='tied')\n",
        "#     gmm.fit(iris_data.data)\n",
        "#     labels = gmm.predict(iris_data.data)\n",
        "#     silhouette_avg = silhouette_score(iris_data.data, labels)\n",
        "#     silhouettes.append(silhouette_avg)\n",
        "#     display_gmm2(gmm,iris_data.data)\n",
        "\n",
        "# # Plot silhouette scores\n",
        "# plt.plot(range(2, 10), silhouettes, marker='o')\n",
        "# plt.xlabel('Number of components')\n",
        "# plt.ylabel('Silhouette Score')\n",
        "# plt.title('Silhouette Score vs Number of Components')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Fit a Gaussian Mixture Model\n",
        "# silhouettes = []\n",
        "# for i in range(2,10):\n",
        "#     gmm = GaussianMixture(n_components=i, covariance_type='diag')\n",
        "#     gmm.fit(iris_data.data)\n",
        "#     labels = gmm.predict(iris_data.data)\n",
        "#     silhouette_avg = silhouette_score(iris_data.data, labels)\n",
        "#     silhouettes.append(silhouette_avg)\n",
        "#     display_gmm2(gmm,iris_data.data)\n",
        "\n",
        "# # Plot silhouette scores\n",
        "# plt.plot(range(2, 10), silhouettes, marker='o')\n",
        "# plt.xlabel('Number of components')\n",
        "# plt.ylabel('Silhouette Score')\n",
        "# plt.title('Silhouette Score vs Number of Components')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Fit a Gaussian Mixture Model\n",
        "# silhouettes = []\n",
        "# for i in range(2,10):\n",
        "#     gmm = GaussianMixture(n_components=i, covariance_type='spherical')\n",
        "#     gmm.fit(iris_data.data)\n",
        "#     labels = gmm.predict(iris_data.data)\n",
        "#     silhouette_avg = silhouette_score(iris_data.data, labels)\n",
        "#     silhouettes.append(silhouette_avg)\n",
        "#     display_gmm2(gmm,iris_data.data)\n",
        "\n",
        "# # Plot silhouette scores\n",
        "# plt.plot(range(2, 10), silhouettes, marker='o')\n",
        "# plt.xlabel('Number of components')\n",
        "# plt.ylabel('Silhouette Score')\n",
        "# plt.title('Silhouette Score vs Number of Components')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Gaussian Mixture normalized\n",
        "* Use GaussianMixture function to cluster the above data \n",
        "* In GMM change the covariance_type and check the difference in the resulting proabability fit \n",
        "* Use a 2D contour plot to plot the resulting distribution (the components of the GMM) as well as the total Gaussian mixture "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Fit a Gaussian Mixture Model\n",
        "# silhouettes = []\n",
        "# for i in range(2,10):\n",
        "#     gmm = GaussianMixture(n_components=i, covariance_type='full')\n",
        "#     gmm.fit(X_normalized)\n",
        "#     labels = gmm.predict(X_normalized)\n",
        "#     silhouette_avg = silhouette_score(X_normalized, labels)\n",
        "#     silhouettes.append(silhouette_avg)\n",
        "#     display_gmm2(gmm,X_normalized)\n",
        "\n",
        "# # Plot silhouette scores\n",
        "# plt.plot(range(2, 10), silhouettes, marker='o')\n",
        "# plt.xlabel('Number of components')\n",
        "# plt.ylabel('Silhouette Score')\n",
        "# plt.title('Silhouette Score vs Number of Components')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Fit a Gaussian Mixture Model\n",
        "# silhouettes = []\n",
        "# for i in range(2,10):\n",
        "#     gmm = GaussianMixture(n_components=i, covariance_type='tied')\n",
        "#     gmm.fit(X_normalized)\n",
        "#     labels = gmm.predict(X_normalized)\n",
        "#     silhouette_avg = silhouette_score(X_normalized, labels)\n",
        "#     silhouettes.append(silhouette_avg)\n",
        "#     display_gmm2(gmm,X_normalized)\n",
        "\n",
        "# # Plot silhouette scores\n",
        "# plt.plot(range(2, 10), silhouettes, marker='o')\n",
        "# plt.xlabel('Number of components')\n",
        "# plt.ylabel('Silhouette Score')\n",
        "# plt.title('Silhouette Score vs Number of Components')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Fit a Gaussian Mixture Model\n",
        "# silhouettes = []\n",
        "# for i in range(2,10):\n",
        "#     gmm = GaussianMixture(n_components=i, covariance_type='diag')\n",
        "#     gmm.fit(X_normalized)\n",
        "#     labels = gmm.predict(X_normalized)\n",
        "#     silhouette_avg = silhouette_score(X_normalized, labels)\n",
        "#     silhouettes.append(silhouette_avg)\n",
        "#     display_gmm2(gmm,X_normalized)\n",
        "\n",
        "# # Plot silhouette scores\n",
        "# plt.plot(range(2, 10), silhouettes, marker='o')\n",
        "# plt.xlabel('Number of components')\n",
        "# plt.ylabel('Silhouette Score')\n",
        "# plt.title('Silhouette Score vs Number of Components')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Fit a Gaussian Mixture Model\n",
        "# silhouettes = []\n",
        "# for i in range(2,10):\n",
        "#     gmm = GaussianMixture(n_components=i, covariance_type='spherical')\n",
        "#     gmm.fit(X_normalized)\n",
        "#     labels = gmm.predict(X_normalized)\n",
        "#     silhouette_avg = silhouette_score(X_normalized, labels)\n",
        "#     silhouettes.append(silhouette_avg)\n",
        "#     display_gmm2(gmm,X_normalized)\n",
        "\n",
        "# # Plot silhouette scores\n",
        "# plt.plot(range(2, 10), silhouettes, marker='o')\n",
        "# plt.xlabel('Number of components')\n",
        "# plt.ylabel('Silhouette Score')\n",
        "# plt.title('Silhouette Score vs Number of Components')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2oBmWT2udcA"
      },
      "source": [
        "## Customer dataset\n",
        "Repeat all the above on the customer data set "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Kmeans unnormalized data\n",
        "* Use Kmeans with different values of K to cluster the above data \n",
        "* Display the outcome of each value of K \n",
        "* Plot distortion function versus K and choose the approriate value of k \n",
        "* Plot the silhouette_score versus K and use it to choose the best K \n",
        "* Store the silhouette_score for the best K for later comparison with other clustering techniques. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# #Customer dataset\n",
        "# data = pd.read_csv('Customer data.csv')\n",
        "# data = data.drop(data.columns[0], axis=1)\n",
        "# column_labels = data.columns.tolist()\n",
        "# data = data.values\n",
        "# scaler = StandardScaler()\n",
        "# data_normalized = scaler.fit_transform(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# inertias = []\n",
        "# silhouette_avg = []\n",
        "# for i in range(2,11):\n",
        "#     kmeans = KMeans(n_clusters=i) \n",
        "#     kmeans.fit(data)\n",
        "#     print (\"num of clusters:\" , i)\n",
        "#     display_cluster(data,kmeans,i)\n",
        "#     inertias.append(kmeans.inertia_)\n",
        "#     silhouette_avg.append(silhouette_score(data, kmeans.labels_)) \n",
        "\n",
        "# plt.plot(range(2,11), inertias, marker='o')\n",
        "# plt.title('Elbow method')\n",
        "# plt.xlabel('Number of clusters')\n",
        "# plt.ylabel('Inertia')\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "# print(silhouette_avg)\n",
        "# plt.plot(range(2,11),silhouette_avg, marker='o')\n",
        "# plt.xlabel(\"Values of K\") \n",
        "# plt.ylabel(\"Silhouette score\") \n",
        "# plt.title(\"Silhouette analysis For Optimal k\")\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Kmeans normalized data\n",
        "* Use Kmeans with different values of K to cluster the above data \n",
        "* Display the outcome of each value of K \n",
        "* Plot distortion function versus K and choose the approriate value of k \n",
        "* Plot the silhouette_score versus K and use it to choose the best K \n",
        "* Store the silhouette_score for the best K for later comparison with other clustering techniques. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# inertias = []\n",
        "# silhouette_avg = []\n",
        "# for i in range(2,11):\n",
        "#     kmeans = KMeans(n_clusters=i) \n",
        "#     kmeans.fit(data_normalized)\n",
        "#     print (\"num of clusters:\" , i)\n",
        "#     display_cluster(data_normalized,kmeans,i)\n",
        "#     inertias.append(kmeans.inertia_)\n",
        "#     silhouette_avg.append(silhouette_score(data_normalized, kmeans.labels_)) \n",
        "\n",
        "# plt.plot(range(2,11), inertias, marker='o')\n",
        "# plt.title('Elbow method')\n",
        "# plt.xlabel('Number of clusters')\n",
        "# plt.ylabel('Inertia')\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "# print(silhouette_avg)\n",
        "# plt.plot(range(2,11),silhouette_avg, marker='o')\n",
        "# plt.xlabel(\"Values of K\") \n",
        "# plt.ylabel(\"Silhouette score\") \n",
        "# plt.title(\"Silhouette analysis For Optimal k\")\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hierarchal Clustering Unnormalized data\n",
        "* Use AgglomerativeClustering function to  to cluster the above data \n",
        "* In the  AgglomerativeClustering change the following parameters \n",
        "    * Affinity (use euclidean, manhattan and cosine)\n",
        "    * Linkage( use average and single )\n",
        "    * Distance_threshold (try different)\n",
        "* For each of these trials plot the Dendograph , calculate the silhouette_score and display the resulting clusters  \n",
        "* Find the set of paramters that would find result in the best silhouette_score and store this score for later comparison with other clustering techniques. \n",
        "* Record your observation "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# linkage_data = linkage(data, method='single', metric='euclidean')\n",
        "# dendrogram(linkage_data)\n",
        "# plt.show()\n",
        "\n",
        "# num_clusters = []\n",
        "# silhouette_scores = []\n",
        "\n",
        "# distance_threshold =[500,100,1500,2000,2500,4000,5000,6000,7000]\n",
        "# for threshold in distance_threshold:\n",
        "#     cluster = AgglomerativeClustering(n_clusters=None, metric='euclidean', linkage='single', distance_threshold=threshold)\n",
        "#     cluster.fit(data)\n",
        "#     labels = cluster.labels_\n",
        "#     num_clusters.append(len(np.unique(labels)))\n",
        "#     silhouette_avg = silhouette_score(data, labels)\n",
        "#     silhouette_scores.append(silhouette_avg)\n",
        "\n",
        "# # Plotting the results\n",
        "# plt.plot(distance_threshold, silhouette_scores, marker='o')\n",
        "# plt.xlabel('Distance Threshold')\n",
        "# plt.ylabel('Silhouette Score')\n",
        "# plt.title('Silhouette Score vs Distance Threshold')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# linkage_data = linkage(data, method='average', metric='euclidean')\n",
        "# dendrogram(linkage_data)\n",
        "# plt.show()\n",
        "\n",
        "# num_clusters = []\n",
        "# silhouette_scores = []\n",
        "\n",
        "# distance_threshold =[2000,8000,12000,15000,20000,30000,40000,50000,60000,80000]\n",
        "# for threshold in distance_threshold:\n",
        "#     cluster = AgglomerativeClustering(n_clusters=None, metric='euclidean', linkage='average', distance_threshold=threshold)\n",
        "#     cluster.fit(data)\n",
        "#     labels = cluster.labels_\n",
        "#     num_clusters.append(len(np.unique(labels)))\n",
        "#     silhouette_avg = silhouette_score(data, labels)\n",
        "#     silhouette_scores.append(silhouette_avg)\n",
        "\n",
        "# # Plotting the results\n",
        "# plt.plot(distance_threshold, silhouette_scores, marker='o')\n",
        "# plt.xlabel('Distance Threshold')\n",
        "# plt.ylabel('Silhouette Score')\n",
        "# plt.title('Silhouette Score vs Distance Threshold')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# linkage_data = linkage(data, method='single', metric='cityblock')\n",
        "# dendrogram(linkage_data)\n",
        "# plt.show()\n",
        "\n",
        "# num_clusters = []\n",
        "# silhouette_scores = []\n",
        "\n",
        "# distance_threshold =[500,1000,1500,2000,3000,4000,5000,6000,8000,17500]\n",
        "# for threshold in distance_threshold:\n",
        "#     cluster = AgglomerativeClustering(n_clusters=None, metric='cityblock', linkage='single', distance_threshold=threshold)\n",
        "#     cluster.fit(data)\n",
        "#     labels = cluster.labels_\n",
        "#     num_clusters.append(len(np.unique(labels)))\n",
        "#     silhouette_avg = silhouette_score(data, labels)\n",
        "#     silhouette_scores.append(silhouette_avg)\n",
        "\n",
        "# # Plotting the results\n",
        "# plt.plot(distance_threshold, silhouette_scores, marker='o')\n",
        "# plt.xlabel('Distance Threshold')\n",
        "# plt.ylabel('Silhouette Score')\n",
        "# plt.title('Silhouette Score vs Distance Threshold')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# linkage_data = linkage(data, method='average', metric='cityblock')\n",
        "# dendrogram(linkage_data)\n",
        "# plt.show()\n",
        "\n",
        "# num_clusters = []\n",
        "# silhouette_scores = []\n",
        "\n",
        "# distance_threshold =[5000,10000,12000,15000,20000,30000,40000,50000,60000,80000]\n",
        "# for threshold in distance_threshold:\n",
        "#     cluster = AgglomerativeClustering(n_clusters=None, metric='cityblock', linkage='average', distance_threshold=threshold)\n",
        "#     cluster.fit(data)\n",
        "#     labels = cluster.labels_\n",
        "#     num_clusters.append(len(np.unique(labels)))\n",
        "#     silhouette_avg = silhouette_score(data, labels)\n",
        "#     silhouette_scores.append(silhouette_avg)\n",
        "\n",
        "# # Plotting the results\n",
        "# plt.plot(distance_threshold, silhouette_scores, marker='o')\n",
        "# plt.xlabel('Distance Threshold')\n",
        "# plt.ylabel('Silhouette Score')\n",
        "# plt.title('Silhouette Score vs Distance Threshold')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# linkage_data = linkage(data, method='single', metric='cosine')\n",
        "# dendrogram(linkage_data)\n",
        "# plt.show()\n",
        "\n",
        "# num_clusters = []\n",
        "# silhouette_scores = []\n",
        "\n",
        "# distance_threshold =[5000,10000,12000,15000,20000,30000,40000,50000,60000,80000]\n",
        "# for threshold in distance_threshold:\n",
        "#     cluster = AgglomerativeClustering(n_clusters=None, metric='cosine', linkage='single', distance_threshold=threshold)\n",
        "#     cluster.fit(data)\n",
        "#     labels = cluster.labels_\n",
        "#     num_clusters.append(len(np.unique(labels)))\n",
        "#     silhouette_avg = silhouette_score(data, labels)\n",
        "#     silhouette_scores.append(silhouette_avg)\n",
        "\n",
        "# # Plotting the results\n",
        "# plt.plot(distance_threshold, silhouette_scores, marker='o')\n",
        "# plt.xlabel('Distance Threshold')\n",
        "# plt.ylabel('Silhouette Score')\n",
        "# plt.title('Silhouette Score vs Distance Threshold')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# linkage_data = linkage(data, method='average', metric='cosine')\n",
        "# dendrogram(linkage_data)\n",
        "# plt.show()\n",
        "\n",
        "# num_clusters = []\n",
        "# silhouette_scores = []\n",
        "\n",
        "# distance_threshold =[5000,10000,12000,15000,20000,30000,40000,50000,60000,80000]\n",
        "# for threshold in distance_threshold:\n",
        "#     cluster = AgglomerativeClustering(n_clusters=None, metric='cosine', linkage='average', distance_threshold=threshold)\n",
        "#     cluster.fit(data)\n",
        "#     labels = cluster.labels_\n",
        "#     num_clusters.append(len(np.unique(labels)))\n",
        "#     silhouette_avg = silhouette_score(data, labels)\n",
        "#     silhouette_scores.append(silhouette_avg)\n",
        "\n",
        "# # Plotting the results\n",
        "# plt.plot(distance_threshold, silhouette_scores, marker='o')\n",
        "# plt.xlabel('Distance Threshold')\n",
        "# plt.ylabel('Silhouette Score')\n",
        "# plt.title('Silhouette Score vs Distance Threshold')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hierarchal Clustering Normalized data\n",
        "* Use AgglomerativeClustering function to  to cluster the above data \n",
        "* In the  AgglomerativeClustering change the following parameters \n",
        "    * Affinity (use euclidean, manhattan and cosine)\n",
        "    * Linkage( use average and single )\n",
        "    * Distance_threshold (try different)\n",
        "* For each of these trials plot the Dendograph , calculate the silhouette_score and display the resulting clusters  \n",
        "* Find the set of paramters that would find result in the best silhouette_score and store this score for later comparison with other clustering techniques. \n",
        "* Record your observation "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# linkage_data = linkage(data, method='single', metric='euclidean')\n",
        "# dendrogram(linkage_data)\n",
        "# plt.show()\n",
        "\n",
        "# num_clusters = []\n",
        "# silhouette_scores = []\n",
        "\n",
        "# distance_threshold =[1000,1500,2000,2500,4000,5000,6000,7000]\n",
        "# for threshold in distance_threshold:\n",
        "#     cluster = AgglomerativeClustering(n_clusters=None, metric='euclidean', linkage='single', distance_threshold=threshold)\n",
        "#     cluster.fit(data_normalized)\n",
        "#     labels = cluster.labels_\n",
        "#     num_clusters.append(len(np.unique(labels)))\n",
        "#     silhouette_avg = silhouette_score(data_normalized, labels)\n",
        "#     silhouette_scores.append(silhouette_avg)\n",
        "\n",
        "# # Plotting the results\n",
        "# plt.plot(distance_threshold, silhouette_scores, marker='o')\n",
        "# plt.xlabel('Distance Threshold')\n",
        "# plt.ylabel('Silhouette Score')\n",
        "# plt.title('Silhouette Score vs Distance Threshold')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# linkage_data = linkage(data, method='average', metric='euclidean')\n",
        "# dendrogram(linkage_data)\n",
        "# plt.show()\n",
        "\n",
        "# num_clusters = []\n",
        "# silhouette_scores = []\n",
        "\n",
        "# distance_threshold =[5000,10000,15000,20000,25000,40000,60000,70000]\n",
        "# for threshold in distance_threshold:\n",
        "#     cluster = AgglomerativeClustering(n_clusters=None, metric='euclidean', linkage='average', distance_threshold=threshold)\n",
        "#     cluster.fit(data_normalized)\n",
        "#     labels = cluster.labels_\n",
        "#     num_clusters.append(len(np.unique(labels)))\n",
        "#     silhouette_avg = silhouette_score(data_normalized, labels)\n",
        "#     silhouette_scores.append(silhouette_avg)\n",
        "\n",
        "# # Plotting the results\n",
        "# plt.plot(distance_threshold, silhouette_scores, marker='o')\n",
        "# plt.xlabel('Distance Threshold')\n",
        "# plt.ylabel('Silhouette Score')\n",
        "# plt.title('Silhouette Score vs Distance Threshold')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# linkage_data = linkage(data, method='single', metric='cityblock')\n",
        "# dendrogram(linkage_data)\n",
        "# plt.show()\n",
        "\n",
        "# num_clusters = []\n",
        "# silhouette_scores = []\n",
        "\n",
        "# distance_threshold =[500,100,1500,2000,2500,4000,5000,6000,7000]\n",
        "# for threshold in distance_threshold:\n",
        "#     cluster = AgglomerativeClustering(n_clusters=None, metric='cityblock', linkage='single', distance_threshold=threshold)\n",
        "#     cluster.fit(data_normalized)\n",
        "#     labels = cluster.labels_\n",
        "#     num_clusters.append(len(np.unique(labels)))\n",
        "#     silhouette_avg = silhouette_score(data_normalized, labels)\n",
        "#     silhouette_scores.append(silhouette_avg)\n",
        "\n",
        "# # Plotting the results\n",
        "# plt.plot(distance_threshold, silhouette_scores, marker='o')\n",
        "# plt.xlabel('Distance Threshold')\n",
        "# plt.ylabel('Silhouette Score')\n",
        "# plt.title('Silhouette Score vs Distance Threshold')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# linkage_data = linkage(data, method='average', metric='cityblock')\n",
        "# dendrogram(linkage_data)\n",
        "# plt.show()\n",
        "\n",
        "# num_clusters = []\n",
        "# silhouette_scores = []\n",
        "\n",
        "# distance_threshold =[500,100,1500,2000,2500,4000,5000,6000,7000]\n",
        "# for threshold in distance_threshold:\n",
        "#     cluster = AgglomerativeClustering(n_clusters=None, metric='cityblock', linkage='average', distance_threshold=threshold)\n",
        "#     cluster.fit(data_normalized)\n",
        "#     labels = cluster.labels_\n",
        "#     num_clusters.append(len(np.unique(labels)))\n",
        "#     silhouette_avg = silhouette_score(data_normalized, labels)\n",
        "#     silhouette_scores.append(silhouette_avg)\n",
        "\n",
        "# # Plotting the results\n",
        "# plt.plot(distance_threshold, silhouette_scores, marker='o')\n",
        "# plt.xlabel('Distance Threshold')\n",
        "# plt.ylabel('Silhouette Score')\n",
        "# plt.title('Silhouette Score vs Distance Threshold')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# linkage_data = linkage(data, method='single', metric='cosine')\n",
        "# dendrogram(linkage_data)\n",
        "# plt.show()\n",
        "\n",
        "# num_clusters = []\n",
        "# silhouette_scores = []\n",
        "\n",
        "# distance_threshold =[0.1e-9,0.2e-9,0.3e-9,0.4e-9,0.5e-9,0.6e-9]\n",
        "# for threshold in distance_threshold:\n",
        "#     cluster = AgglomerativeClustering(n_clusters=None, metric='cosine', linkage='single', distance_threshold=threshold)\n",
        "#     cluster.fit(data_normalized)\n",
        "#     labels = cluster.labels_\n",
        "#     num_clusters.append(len(np.unique(labels)))\n",
        "#     silhouette_avg = silhouette_score(data_normalized, labels)\n",
        "#     silhouette_scores.append(silhouette_avg)\n",
        "\n",
        "# # Plotting the results\n",
        "# plt.plot(distance_threshold, silhouette_scores, marker='o')\n",
        "# plt.xlabel('Distance Threshold')\n",
        "# plt.ylabel('Silhouette Score')\n",
        "# plt.title('Silhouette Score vs Distance Threshold')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# linkage_data = linkage(data, method='average', metric='cosine')\n",
        "# dendrogram(linkage_data)\n",
        "# plt.show()\n",
        "\n",
        "# num_clusters = []\n",
        "# silhouette_scores = []\n",
        "\n",
        "# distance_threshold =[500,100,1500,2000,2500,4000,5000,6000,7000]\n",
        "# for threshold in distance_threshold:\n",
        "#     cluster = AgglomerativeClustering(n_clusters=None, metric='cosine', linkage='average', distance_threshold=threshold)\n",
        "#     cluster.fit(data_normalized)\n",
        "#     labels = cluster.labels_\n",
        "#     num_clusters.append(len(np.unique(labels)))\n",
        "#     silhouette_avg = silhouette_score(data_normalized, labels)\n",
        "#     silhouette_scores.append(silhouette_avg)\n",
        "\n",
        "# # Plotting the results\n",
        "# plt.plot(distance_threshold, silhouette_scores, marker='o')\n",
        "# plt.xlabel('Distance Threshold')\n",
        "# plt.ylabel('Silhouette Score')\n",
        "# plt.title('Silhouette Score vs Distance Threshold')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### DBScan Unnormalized data\n",
        "* Use DBScan function to  to cluster the above data \n",
        "* In the  DBscan change the following parameters \n",
        "    * EPS (from 0.1 to 3)\n",
        "    * Min_samples (from 5 to 25)\n",
        "* Plot the silhouette_score versus the variation in the EPS and the min_samples\n",
        "* Plot the resulting Clusters in this case \n",
        "* Find the set of paramters that would find result in the best silhouette_score and store this score for later comparison with other clustering techniques. \n",
        "* Record your observations and comments "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Define range of EPS and min_samples values\n",
        "# eps_values = np.arange(0.3, 1.3, 0.1)\n",
        "# min_samples_values = np.arange(5, 26, 5)\n",
        "\n",
        "# # Initialize variables to store best parameters and corresponding silhouette score\n",
        "# best_eps = None\n",
        "# best_min_samples = None\n",
        "# best_score = -1\n",
        "\n",
        "# # Initialize lists to store silhouette scores for plotting\n",
        "# silhouette_scores = []\n",
        "\n",
        "# # Loop over different combinations of EPS and min_samples\n",
        "# for eps in eps_values:\n",
        "#     for min_samples in min_samples_values:\n",
        "#         # Perform DBScan clustering\n",
        "#         dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
        "#         labels = dbscan.fit_predict(data)\n",
        "#         print(labels)\n",
        "#         if(len(np.unique(dbscan.labels_)) < 20):\n",
        "#             display_db(data,dbscan,num_clusters = len(np.unique(dbscan.labels_)))\n",
        "#         # Compute silhouette score\n",
        "#         if(len(np.unique(dbscan.labels_)) > 1):\n",
        "#             score = silhouette_score(data, labels)\n",
        "#             silhouette_scores.append(score)\n",
        "        \n",
        "#         # Check if current parameters yield the best silhouette score\n",
        "#         if score > best_score:\n",
        "#             best_eps = eps\n",
        "#             best_min_samples = min_samples\n",
        "#             best_score = score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### DBScan normalized data\n",
        "* Use DBScan function to  to cluster the above data \n",
        "* In the  DBscan change the following parameters \n",
        "    * EPS (from 0.1 to 3)\n",
        "    * Min_samples (from 5 to 25)\n",
        "* Plot the silhouette_score versus the variation in the EPS and the min_samples\n",
        "* Plot the resulting Clusters in this case \n",
        "* Find the set of paramters that would find result in the best silhouette_score and store this score for later comparison with other clustering techniques. \n",
        "* Record your observations and comments "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Define range of EPS and min_samples values\n",
        "# eps_values = np.arange(0.3, 1.3, 0.1)\n",
        "# min_samples_values = np.arange(5, 26, 5)\n",
        "\n",
        "# # Initialize variables to store best parameters and corresponding silhouette score\n",
        "# best_eps = None\n",
        "# best_min_samples = None\n",
        "# best_score = -1\n",
        "\n",
        "# # Initialize lists to store silhouette scores for plotting\n",
        "# silhouette_scores = []\n",
        "\n",
        "# # Loop over different combinations of EPS and min_samples\n",
        "# for eps in eps_values:\n",
        "#     for min_samples in min_samples_values:\n",
        "#         # Perform DBScan clustering\n",
        "#         dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
        "#         labels = dbscan.fit_predict(data_normalized)\n",
        "#         print(labels)\n",
        "#         if(len(np.unique(dbscan.labels_)) < 20):\n",
        "#             display_db(data_normalized,dbscan,num_clusters = len(np.unique(dbscan.labels_)))\n",
        "#         # Compute silhouette score\n",
        "#         if(len(np.unique(dbscan.labels_)) > 1):\n",
        "#             score = silhouette_score(data_normalized, labels)\n",
        "#             silhouette_scores.append(score)\n",
        "        \n",
        "#         # Check if current parameters yield the best silhouette score\n",
        "#         if score > best_score:\n",
        "#             best_eps = eps\n",
        "#             best_min_samples = min_samples\n",
        "#             best_score = score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Gaussian Mixture unnormalized\n",
        "* Use GaussianMixture function to cluster the above data \n",
        "* In GMM change the covariance_type and check the difference in the resulting proabability fit \n",
        "* Use a 2D contour plot to plot the resulting distribution (the components of the GMM) as well as the total Gaussian mixture "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Fit a Gaussian Mixture Model\n",
        "# silhouettes = []\n",
        "# for i in range(2,10):\n",
        "#     gmm = GaussianMixture(n_components=i, covariance_type='full')\n",
        "#     gmm.fit(data)\n",
        "#     labels = gmm.predict(data)\n",
        "#     silhouette_avg = silhouette_score(data, labels)\n",
        "#     silhouettes.append(silhouette_avg)\n",
        "#     #display_gmm2(gmm,data)\n",
        "\n",
        "# # Plot silhouette scores\n",
        "# plt.plot(range(2, 10), silhouettes, marker='o')\n",
        "# plt.xlabel('Number of components')\n",
        "# plt.ylabel('Silhouette Score')\n",
        "# plt.title('Silhouette Score vs Number of Components')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Fit a Gaussian Mixture Model\n",
        "# silhouettes = []\n",
        "# for i in range(2,10):\n",
        "#     gmm = GaussianMixture(n_components=i, covariance_type='tied')\n",
        "#     gmm.fit(data)\n",
        "#     labels = gmm.predict(data)\n",
        "#     silhouette_avg = silhouette_score(data, labels)\n",
        "#     silhouettes.append(silhouette_avg)\n",
        "#     #display_gmm2(gmm,data)\n",
        "\n",
        "# # Plot silhouette scores\n",
        "# plt.plot(range(2, 10), silhouettes, marker='o')\n",
        "# plt.xlabel('Number of components')\n",
        "# plt.ylabel('Silhouette Score')\n",
        "# plt.title('Silhouette Score vs Number of Components')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Fit a Gaussian Mixture Model\n",
        "# silhouettes = []\n",
        "# for i in range(2,10):\n",
        "#     gmm = GaussianMixture(n_components=i, covariance_type='diag')\n",
        "#     gmm.fit(data)\n",
        "#     labels = gmm.predict(data)\n",
        "#     silhouette_avg = silhouette_score(data, labels)\n",
        "#     silhouettes.append(silhouette_avg)\n",
        "#     #display_gmm2(gmm,data)\n",
        "\n",
        "# # Plot silhouette scores\n",
        "# plt.plot(range(2, 10), silhouettes, marker='o')\n",
        "# plt.xlabel('Number of components')\n",
        "# plt.ylabel('Silhouette Score')\n",
        "# plt.title('Silhouette Score vs Number of Components')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Fit a Gaussian Mixture Model\n",
        "# silhouettes = []\n",
        "# for i in range(2,10):\n",
        "#     gmm = GaussianMixture(n_components=i, covariance_type='spherical')\n",
        "#     gmm.fit(data)\n",
        "#     labels = gmm.predict(data)\n",
        "#     silhouette_avg = silhouette_score(data, labels)\n",
        "#     silhouettes.append(silhouette_avg)\n",
        "#     #display_gmm2(gmm,data)\n",
        "\n",
        "# # Plot silhouette scores\n",
        "# plt.plot(range(2, 10), silhouettes, marker='o')\n",
        "# plt.xlabel('Number of components')\n",
        "# plt.ylabel('Silhouette Score')\n",
        "# plt.title('Silhouette Score vs Number of Components')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Gaussian Mixture normalized\n",
        "* Use GaussianMixture function to cluster the above data \n",
        "* In GMM change the covariance_type and check the difference in the resulting proabability fit \n",
        "* Use a 2D contour plot to plot the resulting distribution (the components of the GMM) as well as the total Gaussian mixture "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Fit a Gaussian Mixture Model\n",
        "# silhouettes = []\n",
        "# for i in range(2,10):\n",
        "#     gmm = GaussianMixture(n_components=i, covariance_type='full')\n",
        "#     gmm.fit(data_normalized)\n",
        "#     labels = gmm.predict(data_normalized)\n",
        "#     silhouette_avg = silhouette_score(data_normalized, labels)\n",
        "#     silhouettes.append(silhouette_avg)\n",
        "#     #display_gmm2(gmm,data_normalized)\n",
        "\n",
        "# # Plot silhouette scores\n",
        "# plt.plot(range(2, 10), silhouettes, marker='o')\n",
        "# plt.xlabel('Number of components')\n",
        "# plt.ylabel('Silhouette Score')\n",
        "# plt.title('Silhouette Score vs Number of Components')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Fit a Gaussian Mixture Model\n",
        "# silhouettes = []\n",
        "# for i in range(2,10):\n",
        "#     gmm = GaussianMixture(n_components=i, covariance_type='tied')\n",
        "#     gmm.fit(data_normalized)\n",
        "#     labels = gmm.predict(data_normalized)\n",
        "#     silhouette_avg = silhouette_score(data_normalized, labels)\n",
        "#     silhouettes.append(silhouette_avg)\n",
        "#     #display_gmm2(gmm,data_normalized)\n",
        "\n",
        "# # Plot silhouette scores\n",
        "# plt.plot(range(2, 10), silhouettes, marker='o')\n",
        "# plt.xlabel('Number of components')\n",
        "# plt.ylabel('Silhouette Score')\n",
        "# plt.title('Silhouette Score vs Number of Components')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Fit a Gaussian Mixture Model\n",
        "# silhouettes = []\n",
        "# for i in range(2,10):\n",
        "#     gmm = GaussianMixture(n_components=i, covariance_type='diag')\n",
        "#     gmm.fit(data_normalized)\n",
        "#     labels = gmm.predict(data_normalized)\n",
        "#     silhouette_avg = silhouette_score(data_normalized, labels)\n",
        "#     silhouettes.append(silhouette_avg)\n",
        "#     #display_gmm2(gmm,data_normalized)\n",
        "\n",
        "# # Plot silhouette scores\n",
        "# plt.plot(range(2, 10), silhouettes, marker='o')\n",
        "# plt.xlabel('Number of components')\n",
        "# plt.ylabel('Silhouette Score')\n",
        "# plt.title('Silhouette Score vs Number of Components')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Fit a Gaussian Mixture Model\n",
        "# silhouettes = []\n",
        "# for i in range(2,10):\n",
        "#     gmm = GaussianMixture(n_components=i, covariance_type='spherical')\n",
        "#     gmm.fit(data_normalized)\n",
        "#     labels = gmm.predict(data_normalized)\n",
        "#     silhouette_avg = silhouette_score(data_normalized, labels)\n",
        "#     silhouettes.append(silhouette_avg)\n",
        "#     #display_gmm2(gmm,data_normalized)\n",
        "\n",
        "# # Plot silhouette scores\n",
        "# plt.plot(range(2, 10), silhouettes, marker='o')\n",
        "# plt.xlabel('Number of components')\n",
        "# plt.ylabel('Silhouette Score')\n",
        "# plt.title('Silhouette Score vs Number of Components')\n",
        "# plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Clustering Project.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
